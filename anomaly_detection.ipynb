{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c36bc54-a1f0-4449-a8cc-0e0973c83668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from emmv import emmv_scores\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.auto_encoder import AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1509960a-5405-443d-a3dc-d05c04d31f44",
   "metadata": {},
   "source": [
    "# **Data Prepocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ba93f-a2a4-4462-8d4d-25bfe100c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and concatenate data\n",
    "df2018 = pd.read_csv('./2018Floor5.csv')\n",
    "df2019 = pd.read_csv('./2019Floor5.csv')\n",
    "df = pd.concat([df2018, df2019], ignore_index=True)\n",
    "\n",
    "# Transform data\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "energy = df[['Date', 'z1_AC4(kW)']].copy()\n",
    "energy.rename(columns={'z1_AC4(kW)': 'y'}, inplace=True)\n",
    "\n",
    "# Set index and resample to hourly, summing and scaling by 1/60\n",
    "energy.set_index('Date', inplace=True)\n",
    "energy = energy.resample('d').sum() * (1/60)\n",
    "\n",
    "# Extract features after resampling\n",
    "energy['lag_7'] = energy['y'].shift(7)\n",
    "# energy['hour'] = energy.index.hour\n",
    "energy['day_of_week'] = energy.index.dayofweek\n",
    "energy['is_weekend'] = energy['day_of_week'].isin([5, 6]).astype(int)\n",
    "energy['rolling_mean'] = energy['y'].rolling(7).mean()\n",
    "energy['rolling_std'] = energy['y'].rolling(7).std()\n",
    "\n",
    "energy = energy.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cecb4e-13eb-4dd3-b770-1d7da3f0ae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc040ada-4f62-448f-acfd-ff2dcd97ab72",
   "metadata": {},
   "source": [
    "# **Data Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4504afd-d00b-4f3c-8414-4c44a1e1114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start = \"2018-07-01\"\n",
    "train_end = \"2018-09-30\"\n",
    "test_start = \"2018-10-1\"\n",
    "test_end = \"2019-12-31\"\n",
    "df_train = energy.loc[train_start:train_end]\n",
    "df_test = energy.loc[test_start:test_end]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db58b6e4-221e-486c-b1be-3cdc3ab77068",
   "metadata": {},
   "source": [
    "# **Pelatihan dan Pengujian**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439a92c0-cf73-4614-aa0e-cab5d983f35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(model, df_train, df_test):\n",
    "    scaler = StandardScaler()\n",
    "    df_train_scaled = scaler.fit_transform(df_train)\n",
    "    df_test_scaled = scaler.transform(df_test)\n",
    "\n",
    "    model.fit(df_train_scaled)\n",
    "    pred = model.predict(df_test_scaled)\n",
    "    anomalies = df_test[pred == 1]\n",
    "    normal = df_test[pred == 0]\n",
    "    score = model.decision_function(df_test_scaled)\n",
    "\n",
    "    return model, pred, anomalies, normal, score, df_train_scaled, df_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332077fb-de93-4554-a2c1-d973fd9a9cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df_test, score, pred, threshold):\n",
    "\n",
    "    #threshold = np.min(score[pred == 1])\n",
    "    print(f\"Total data: {len(df_test)}\")\n",
    "    print(f\"Anomali: {len(df_test[pred==1])}\")\n",
    "    print(f\"Normal: {len(df_test[pred==0])}\")\n",
    "\n",
    "    print(\"\\nDaftar waktu point anomaly:\")\n",
    "    anomaly_times = df_test.index[pred == 1]\n",
    "    for i, time in enumerate(anomaly_times, 1):\n",
    "        print(f\"  - Anomali {i}: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "    axs[0].plot(df_test.index, df_test['y'], color='blue', label='Original data')\n",
    "    axs[0].scatter(df_test.index[pred==1], df_test.y[pred==1], color='red', label='Anomalies')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid()\n",
    "\n",
    "    axs[1].plot(df_test.index, score, color='blue', label='Anomaly Score')\n",
    "    axs[1].axhline(y=threshold, color='green', linestyle='--', label=f'Threshold ({threshold:.3e})')\n",
    "    axs[1].scatter(df_test.index[pred == 1], score[pred == 1], color='red', label='Anomalies')\n",
    "    axs[1].set_title('Anomaly Score')\n",
    "    axs[1].legend()\n",
    "    axs[1].grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea679c3-8341-4dae-b651-d1cb698888f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collective_anomaly_ranges(preds, timestamps):\n",
    "    ranges = []\n",
    "    start = None\n",
    "    for i, val in enumerate(preds):\n",
    "        if val == 1 and start is None:\n",
    "            start = timestamps[i]\n",
    "        elif val == 0 and start is not None:\n",
    "            #end = timestamps[i]: kalo mau \"anomali berlangsung sampai data kembali normal\"\n",
    "            #end = timestamps[i-1]: kalo mau rangenya hanya mencakup data yang memang anomali\n",
    "            end = timestamps[i]\n",
    "            ranges.append((start, end))\n",
    "            start = None\n",
    "    if start is not None:\n",
    "        ranges.append((start, timestamps[-1]))\n",
    "    return ranges\n",
    "\n",
    "def plot_collective(df_test, score, pred, threshold):\n",
    "    print(f\"Total data: {len(df_test)}\")\n",
    "    print(f\"Anomali: {len(df_test[pred==1])}\")\n",
    "    print(f\"Normal: {len(df_test[pred==0])}\")\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(16, 8))\n",
    "\n",
    "    axs[0].plot(df_test.index, df_test['y'], color='blue', label='Original Data')\n",
    "\n",
    "    ranges = get_collective_anomaly_ranges(pred, df_test.index)\n",
    "    print(\"\\nDaftar kolektif anomali:\")\n",
    "    for i, (start, end) in enumerate(ranges, 1):\n",
    "        print(f\"  - Anomali {i}: {start.strftime('%Y-%m-%d %H:%M')} â†’ {end.strftime('%Y-%m-%d %H:%M')}\")\n",
    "        axs[0].axvspan(start, end, color='red', alpha=0.3)\n",
    "\n",
    "    axs[0].set_title('Data')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid()\n",
    "\n",
    "    # Plot skor anomali\n",
    "    axs[1].plot(df_test.index, score, color='blue', label='Anomaly Score')\n",
    "    axs[1].axhline(y=threshold, color='green', linestyle='--', label=f'Threshold ({threshold:.3e})')\n",
    "    axs[1].scatter(df_test.index[pred == 1], score[pred == 1], color='red', s=10, label='Anomaly Points')\n",
    "    for start, end in ranges:\n",
    "        axs[1].axvspan(start, end, color='red', alpha=0.3)\n",
    "        \n",
    "    axs[1].set_title('Anomaly Score')\n",
    "    axs[1].legend()\n",
    "    axs[1].grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d232a18-718f-46bf-b655-735d7fba264e",
   "metadata": {},
   "source": [
    "## **Isolation Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa676c9-9259-41b2-a281-0c3a087753e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if_model, if_pred, if_anomalies, if_normal, if_score, train_scaled, test_scaled = apply_model(IForest(contamination=0.01, random_state=1), df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d566fc93-f0af-432d-b7e6-a74d3f00eb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df_train, if_model.decision_scores_, if_model.labels_, if_model.threshold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64e6e37-19ad-4406-9843-bf12ded100dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot(df_test, if_score, if_pred, if_model.threshold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d21e15f-af58-4105-b987-5d2d7db5ba00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_collective(df_test, if_score, if_pred, if_model.threshold_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f37d139-872d-4424-89de-00c43fa9366d",
   "metadata": {},
   "source": [
    "## **LOF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bffe57-5243-4f65-8993-0c24fd0fe46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lof_model, lof_pred, lof_anomalies, lof_normal, lof_score, train_scaled, test_scaled = apply_model(LOF(contamination=0.01, novelty=True), df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b812c7c-765a-41ba-9edd-4de2a9f58686",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df_train, lof_model.decision_scores_, lof_model.labels_, lof_model.threshold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe52f4ba-35b8-4e57-b482-ef3a6f9a3fc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot(df_test, lof_score, lof_pred, lof_model.threshold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4568fb-f318-4e45-b2eb-f3eac6444d83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_collective(df_test, lof_score, lof_pred, lof_model.threshold_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2eb38b-168a-452e-afb9-87ccb164b91d",
   "metadata": {},
   "source": [
    "## **AutoEncoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecee563-f2c9-438b-93db-93e492d8c7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_model, ae_pred, ae_anomalies, ae_normal, ae_score, train_scaled, test_scaled = apply_model(AutoEncoder(contamination = 0.01), df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44a03fc-cade-468e-bd06-f80485fe73b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df_train, ae_model.decision_scores_, ae_model.labels_, ae_model.threshold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169640e1-de19-4793-9bdd-3d5d997b7d56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot(df_test, ae_score, ae_pred, ae_model.threshold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2755fdd5-837d-417a-9e3c-50bff94a0856",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_collective(df_test, ae_score, ae_pred, ae_model.threshold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafef42f-3ce9-4ada-b4a4-db3f68d2658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(ae_model, 'ae_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8469088-2fe5-4475-8937-bad5bae0a5fd",
   "metadata": {},
   "source": [
    "## **OneClassSVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f650936e-12fd-4503-b671-cfe28012c3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocsvm_model, ocsvm_pred, ocsvm_anomalies, ocsvm_normal, ocsvm_score, train_scaled, test_scaled = apply_model(OCSVM(contamination=0.01), df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd246d-9a9c-4c8e-8c31-a3684bad1283",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df_train, ocsvm_model.decision_scores_, ocsvm_model.labels_, ocsvm_model.threshold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e7dec3-2eea-4c55-8413-dc7cdeb23c3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot(df_test, ocsvm_score, ocsvm_pred, ocsvm_model.threshold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5191f3df-708c-457b-8027-78577be5c207",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_collective(df_test, ocsvm_score, ocsvm_pred, ocsvm_model.threshold_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50041570-939c-455f-8609-8c7047a81d6c",
   "metadata": {},
   "source": [
    "## **KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e391fd6-23a9-462f-96a7-d46b3ce72839",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model, knn_pred, knn_anomalies, knn_normal, knn_score, train_scaled, test_scaled = apply_model(KNN(contamination=0.01), df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e713cb-322d-4c7c-a3ce-faceea3a1b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df_train, knn_model.decision_scores_, knn_model.labels_, knn_model.threshold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bcde47-b876-404d-8570-deab866a236c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot(df_test, knn_score, knn_pred, knn_model.threshold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a75035f-5d1c-4d41-934e-9b625feb37cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_collective(df_test, knn_score, knn_pred, knn_model.threshold_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76d97b7-f07f-4756-a59d-bedc31787cf5",
   "metadata": {},
   "source": [
    "# **EMMV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393d8bc4-09b3-458b-8893-829008908021",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_generated = 10000\n",
    "alpha_min = 0.005\n",
    "alpha_max = 0.999\n",
    "t_max = 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6629388-1fc2-4178-80b8-59265c8adb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hitung exess mass\n",
    "def em(t, t_max, volume_support, s_unif, s_X, n_generated):\n",
    "    # inisialisasi array untuk simpan nilai em\n",
    "    EM_t = np.zeros(t.shape[0]) \n",
    "    # jumlah data dalam data test\n",
    "    n_samples = s_X.shape[0]\n",
    "    # nilai unik dari skor anomali data test\n",
    "    s_X_unique = np.unique(s_X)\n",
    "    EM_t[0] = 1.\n",
    "    for u in s_X_unique:\n",
    "        # hitung excess mass dengan mengurangi massa aktual dan massa uniform yang dikali penalti (t)\n",
    "        EM_t = np.maximum(EM_t, 1. / n_samples * (s_X > u).sum() -\n",
    "                          t * (s_unif > u).sum() / n_generated * volume_support)\n",
    "    amax = np.argmax(EM_t <= t_max) + 1\n",
    "    if amax == 1:\n",
    "        print('\\nFailed to achieve t_max\\n')\n",
    "        amax = -1\n",
    "    AUC = auc(t[:amax], EM_t[:amax])\n",
    "    return AUC, EM_t, amax\n",
    "\n",
    "# hitung mass volume\n",
    "def mv(axis_alpha, volume_support, s_unif, s_X, n_generated):\n",
    "    # jumlah data dalam data test\n",
    "    n_samples = s_X.shape[0]\n",
    "    # skor anomalinya diurutin dari kecil ke besar\n",
    "    s_X_argsort = s_X.argsort()\n",
    "    mass = 0\n",
    "    cpt = 0\n",
    "    # ambang batas awal diambil skor anomali yang terbesar\n",
    "    u = s_X[s_X_argsort[-1]]\n",
    "    # inisialisasi array untuk simpan nilai mv\n",
    "    mv = np.zeros(axis_alpha.shape[0])\n",
    "    for i in range(axis_alpha.shape[0]):\n",
    "        while mass < axis_alpha[i]:\n",
    "            cpt += 1\n",
    "            u = s_X[s_X_argsort[-cpt]]\n",
    "            mass = 1. / n_samples * cpt\n",
    "        # hitung volume berdasarkan proporsi data uniform yang lebih dari sm dengan ambang (u)\n",
    "        mv[i] = float((s_unif >= u).sum()) / n_generated * volume_support\n",
    "    return auc(axis_alpha, mv), mv\n",
    "\n",
    "def compute_em_mv(model, df_train_scaled, df_test_scaled, score, n_generated, alpha_min, alpha_max, t_max):\n",
    "    n_samples, n_features = df_test_scaled.shape\n",
    "\n",
    "    X_train_ = df_train_scaled\n",
    "    X_ = df_test_scaled\n",
    "    # skor anomali data test, dikasi min soalnya kebalikan dengan scikit learn\n",
    "    s_X = -score  \n",
    "    \n",
    "    # nilai min setiap fitur dari data test\n",
    "    lim_inf = X_.min(axis=0)\n",
    "    # nilai maks setiap fitur dari data test\n",
    "    lim_sup = X_.max(axis=0)\n",
    "    #hitung volume support dengan mengalikan seluruh selisih nilai maks dan min setiap fitur\n",
    "    volume_support = (lim_sup - lim_inf).prod()\n",
    "    # array skala pinalti untuk menentukan seberapa ketat mendeteksi anomali\n",
    "    t = np.arange(0, 100 / volume_support, 0.001 / volume_support)\n",
    "    # array proporsi massa untuk mv\n",
    "    axis_alpha = np.arange(alpha_min, alpha_max, 0.001)\n",
    "    # buat data acak uniform dalam rentang fitur pengujian\n",
    "    unif = np.random.uniform(lim_inf, lim_sup, size=(n_generated, n_features))\n",
    "    s_unif = -model.decision_function(unif)\n",
    "\n",
    "    em_auc, em_t, amax = em(t, t_max, volume_support, s_unif, s_X, n_generated)\n",
    "    mv_auc, mv_curve = mv(axis_alpha, volume_support, s_unif, s_X, n_generated)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(t[:amax], em_t[:amax], label=f'em_score = {em_auc:.3e}')\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel('EM(t)')\n",
    "    plt.title('Excess-Mass Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.plot(axis_alpha, mv_curve, label=f'mv_score = {mv_auc:.3e}')\n",
    "    plt.xlabel('alpha')\n",
    "    plt.ylabel('MV(alpha)')\n",
    "    plt.title('Mass-Volume Curve')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return em_auc, mv_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8025f414-0f69-4c84-af4d-a66604076c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_value_if, mv_value_if = compute_em_mv(if_model, train_scaled, test_scaled, if_score, n_generated, alpha_min, alpha_max, t_max)\n",
    "print(f\"EM: {em_value_if:.4e}, MV: {mv_value_if:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf93af0-6469-4bf0-a5bf-8da44915528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_value_lof, mv_value_lof = compute_em_mv(lof_model, train_scaled, test_scaled, lof_score, n_generated, alpha_min, alpha_max, t_max)\n",
    "print(f\"EM: {em_value_lof:.4e}, MV: {mv_value_lof:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d898f1f2-0c5d-4e99-81f8-4d6ddebfd423",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_value_ae, mv_value_ae = compute_em_mv(ae_model, train_scaled, test_scaled, ae_score, n_generated, alpha_min, alpha_max, t_max)\n",
    "print(f\"EM: {em_value_ae:.4e}, MV: {mv_value_ae:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f5c10-3c32-40c8-91c1-e01121bb2458",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_value_ocsvm, mv_value_ocsvm = compute_em_mv(ocsvm_model, train_scaled, test_scaled, ocsvm_score, n_generated, alpha_min, alpha_max, t_max)\n",
    "print(f\"EM: {em_value_ocsvm:.4e}, MV: {mv_value_ocsvm:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa0e7ff-4cef-44f8-91b0-ce1c8747e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_value_knn, mv_value_knn = compute_em_mv(knn_model, train_scaled, test_scaled, knn_score, n_generated, alpha_min, alpha_max, t_max)\n",
    "print(f\"EM: {em_value_knn:.4e}, MV: {mv_value_knn:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fd2a01-48c7-4ff4-951f-6c8151204361",
   "metadata": {},
   "outputs": [],
   "source": [
    "emmv_score = pd.DataFrame({\n",
    "    'model': ['Isolation Forest', 'Local Outlier Factor', 'Auto Encoder', 'OneClass SVM', 'KNN'], \n",
    "    'Excess Mass': [em_value_if, em_value_lof, em_value_ae, em_value_ocsvm, em_value_knn],\n",
    "    'Mass Volume': [mv_value_if, mv_value_lof, mv_value_ae, mv_value_ocsvm, mv_value_knn],\n",
    "})\n",
    "emmv_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
